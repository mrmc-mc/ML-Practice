{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e146f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings( \"ignore\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54693922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compare our model's accuracy with sklearn model \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# Logistic Regression \n",
    "class LogitRegression() : \n",
    "\tdef __init__( self, learning_rate, iterations ) :\t\t \n",
    "\t\tself.learning_rate = learning_rate\t\t \n",
    "\t\tself.iterations = iterations \n",
    "\t\t\n",
    "\t# Function for model training\t \n",
    "\tdef fit( self, X, Y ) :\t\t \n",
    "\t\t# no_of_training_examples, no_of_features\t\t \n",
    "\t\tself.m, self.n = X.shape\t\t \n",
    "\t\t# weight initialization\t\t \n",
    "\t\tself.W = np.zeros( self.n )\t\t \n",
    "\t\tself.b = 0\t\t\n",
    "\t\tself.X = X\t\t \n",
    "\t\tself.Y = Y \n",
    "\t\t\n",
    "\t\t# gradient descent learning \n",
    "\t\t\t\t\n",
    "\t\tfor i in range( self.iterations ) :\t\t\t \n",
    "\t\t\tself.update_weights()\t\t\t \n",
    "\t\treturn self\n",
    "\t\n",
    "\t# Helper function to update weights in gradient descent \n",
    "\t\n",
    "\tdef update_weights( self ) :\t\t \n",
    "\t\tA = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) ) \n",
    "\t\t\n",
    "\t\t# calculate gradients\t\t \n",
    "\t\ttmp = ( A - self.Y.T )\t\t \n",
    "\t\ttmp = np.reshape( tmp, self.m )\t\t \n",
    "\t\tdW = np.dot( self.X.T, tmp ) / self.m\t\t \n",
    "\t\tdb = np.sum( tmp ) / self.m \n",
    "\t\t\n",
    "\t\t# update weights\t \n",
    "\t\tself.W = self.W - self.learning_rate * dW\t \n",
    "\t\tself.b = self.b - self.learning_rate * db \n",
    "\t\t\n",
    "\t\treturn self\n",
    "\t\n",
    "\t# Hypothetical function h( x ) \n",
    "\t\n",
    "\tdef predict( self, X ) :\t \n",
    "\t\tZ = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )\t\t \n",
    "\t\tY = np.where( Z > 0.5, 1, 0 )\t\t \n",
    "\t\treturn Y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac24b5a",
   "metadata": {},
   "source": [
    "Driver code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84b72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() : \n",
    "\t\n",
    "\t# Importing dataset\t \n",
    "\tdf = pd.read_csv( \"diabets.csv\", header=0) \n",
    "\tX = df.iloc[:,:-1].values \n",
    "\tY = df.iloc[:,-1:].values \n",
    "\t\n",
    "\t# Splitting dataset into train and test set \n",
    "\tX_train, X_test, Y_train, Y_test = train_test_split( \n",
    "\tX, Y, test_size = 1/3, random_state = 0 ) \n",
    "\t\n",
    "\t# Model training\t \n",
    "\tmodel = LogitRegression( learning_rate = 0.01, iterations = 1000 ) \n",
    "\t\n",
    "\tmodel.fit( X_train, Y_train )\t \n",
    "\tmodel1 = LogisticRegression()\t \n",
    "\tmodel1.fit( X_train, Y_train) \n",
    "\t\n",
    "\t# Prediction on test set \n",
    "\tY_pred = model.predict( X_test )\t \n",
    "\tY_pred1 = model1.predict( X_test ) \n",
    "\t\n",
    "\t# measure performance\t \n",
    "\tcorrectly_classified = 0\t\n",
    "\tcorrectly_classified1 = 0\n",
    "\t\n",
    "\t# counter\t \n",
    "\tcount = 0\t\n",
    "\tfor count in range( np.size( Y_pred ) ) : \n",
    "\t\t\n",
    "\t\tif Y_test[count] == Y_pred[count] :\t\t\t \n",
    "\t\t\tcorrectly_classified = correctly_classified + 1\n",
    "\t\t\n",
    "\t\tif Y_test[count] == Y_pred1[count] :\t\t\t \n",
    "\t\t\tcorrectly_classified1 = correctly_classified1 + 1\n",
    "\t\t\t\n",
    "\t\tcount = count + 1\n",
    "\t\t\n",
    "\tprint( \"Accuracy on test set by our model\t : \", ( \n",
    "\tcorrectly_classified / count ) * 100 ) \n",
    "\tprint( \"Accuracy on test set by sklearn model : \", ( \n",
    "\tcorrectly_classified1 / count ) * 100 ) \n",
    "\n",
    "\n",
    "\tplt.scatter(X[:, -2], Y, color=\"red\",marker=\"o\", label=\"actual-data\")\n",
    "\n",
    "\tplt.plot(X_test[:, -2], Y_pred, marker=\"x\", color=\"black\", label=\"logistic\")\n",
    "\tplt.legend()\n",
    "\tplt.title(\"diabets\")\n",
    "\n",
    "\tplt.xlabel(\"age X\")\n",
    "\n",
    "\tplt.ylabel(\"outcome Y\")\n",
    "\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7588c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" :\t \n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
